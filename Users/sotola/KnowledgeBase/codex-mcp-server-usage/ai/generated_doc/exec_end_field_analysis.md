# turn.exec.end Field Analysis & Limiting Strategy

**Analysis Date:** 2025-11-19
**Log File:** `~/centralized-logs/codex/sse_lines.jsonl`

[Created by Claude: 08c7d791-36f6-4728-86dd-259f9d28a1ef]

## Executive Summary

Yes, **limiting specific payload fields is sufficient** to control `turn.exec.end` event size!

The bloat comes from **3 specific fields** within the SSE payload:
1. `payload.stdout` - Raw stdout from command execution
2. `payload.aggregated_output` - Combined stdout + stderr
3. `payload.formatted_output` - Formatted output (usually smaller)

## Event Structure

### Full Hierarchy

```
turn.exec.end event
â”‚
â”œâ”€ Envelope (JSONL wrapper)
â”‚  â”œâ”€ event: "turn.exec.end"
â”‚  â”œâ”€ t: "2025-11-18T23:10:07.841" (timestamp)
â”‚  â”œâ”€ flow_id: "019a97b0-..."
â”‚  â”œâ”€ sid: "session-id"
â”‚  â”œâ”€ metadata: {...}
â”‚  â””â”€ line: "data: {...}" â† SSE formatted data
â”‚
â””â”€ SSE Line (inside "line" field)
   â””â”€ Parsed JSON: {"type": "turn.exec.end", "payload": {...}}
      â”‚
      â””â”€ payload:
         â”œâ”€ call_id: "call_M0mZY41..." (29 chars) âœ… SMALL
         â”œâ”€ stdout: "..." ðŸ”´ CAN BE HUGE (4.61 MB max)
         â”œâ”€ stderr: "..." âœ… Usually small (8.62 KB max)
         â”œâ”€ aggregated_output: "..." ðŸ”´ HUGE (stdout + stderr)
         â”œâ”€ exit_code: 0 âœ… SMALL
         â”œâ”€ duration: {secs: 0, nanos: 14599500} âœ… SMALL
         â””â”€ formatted_output: "..." âš ï¸ Can be large (12 KB max)
```

## Field Size Analysis (from 947 events)

| Field Path | Avg Size | Max Size | Ratio | Problem? |
|-----------|----------|----------|-------|----------|
| **payload.stdout** | **31.04 KB** | **4.61 MB** | **152x** | ðŸ”´ **YES** |
| **payload.aggregated_output** | **31.09 KB** | **4.61 MB** | **152x** | ðŸ”´ **YES** |
| **payload.formatted_output** | **1.55 KB** | **12.04 KB** | **8x** | âš ï¸ Minor |
| payload.stderr | 48 B | 8.62 KB | 184x | âœ… No |
| payload.call_id | 30 B | 68 B | 2x | âœ… No |
| payload.duration | 30 B | 32 B | 1x | âœ… No |
| payload.exit_code | 1 B | 3 B | 3x | âœ… No |

### Key Observations

1. **stdout and aggregated_output are duplicates** - same content, same size
2. **formatted_output** is usually smaller (1.55 KB avg vs 31 KB)
3. **stderr** is almost always tiny (48 bytes average)
4. **152x ratio** means max is 152 times the average (huge outliers!)

## Root Cause: Command Output Capture

The 96 MB event contains:
```json
{
  "payload": {
    "stdout": "1:{\"event\":\"turn.raw_response_item\",\"t\":\"2025-11-18T21:54:40.874\"...",
    "aggregated_output": "1:{\"event\":\"turn.raw_response_item\",...",
    ...
  }
}
```

This happens when:
1. User runs a command that outputs the entire log file (e.g., `cat sse_lines.jsonl`)
2. Codex captures stdout
3. Stdout contains JSON with escape characters
4. JSON gets double/triple escaped (log within log within log)
5. Size explodes exponentially with each nesting level

## Recommended Limiting Strategy

### Option 1: Truncate Output Fields (RECOMMENDED)

Limit the **character length** of output fields before JSON serialization:

```python
MAX_OUTPUT_LENGTH = 1_000_000  # 1 million chars (~1 MB after JSON encoding)

def truncate_output(output: str, max_length: int = MAX_OUTPUT_LENGTH) -> str:
    """Truncate output with clear marker."""
    if len(output) <= max_length:
        return output

    omitted = len(output) - max_length
    return (
        output[:max_length] +
        f"\n... [output truncated, omitted {omitted:,} characters "
        f"({omitted / 1024 / 1024:.2f} MB)]"
    )

# Apply before creating payload
payload = {
    "call_id": call_id,
    "stdout": truncate_output(stdout),
    "stderr": truncate_output(stderr, max_length=100_000),  # Smaller limit for stderr
    "aggregated_output": truncate_output(aggregated_output),
    "exit_code": exit_code,
    "duration": duration,
    "formatted_output": truncate_output(formatted_output, max_length=50_000),
}
```

**Impact:**
- âœ… Saves 985 MB (top 18 events)
- âœ… Most events unaffected (avg is only 31 KB)
- âœ… Clear truncation markers for debugging
- âœ… Prevents exponential escape bloat
- âœ… Simple to implement

### Option 2: Different Limits by Field

More granular control:

```python
FIELD_LIMITS = {
    "stdout": 1_000_000,      # 1M chars (~1 MB)
    "stderr": 100_000,        # 100K chars (~100 KB)
    "aggregated_output": 1_000_000,  # 1M chars
    "formatted_output": 50_000,      # 50K chars (~50 KB)
}

def truncate_payload_fields(payload: dict) -> dict:
    """Truncate all output fields in payload."""
    for field, max_length in FIELD_LIMITS.items():
        if field in payload and isinstance(payload[field], str):
            original_length = len(payload[field])
            if original_length > max_length:
                omitted = original_length - max_length
                payload[field] = (
                    payload[field][:max_length] +
                    f"\n... [truncated, omitted {omitted:,} chars]"
                )
    return payload
```

### Option 3: Remove Redundant Fields

Since `aggregated_output` duplicates `stdout` + `stderr`:

```python
# Option A: Remove aggregated_output entirely
payload = {
    "call_id": call_id,
    "stdout": truncate_output(stdout, 1_000_000),
    "stderr": truncate_output(stderr, 100_000),
    # "aggregated_output": removed!
    "exit_code": exit_code,
    "duration": duration,
    "formatted_output": truncate_output(formatted_output, 50_000),
}

# Option B: Keep only aggregated_output, remove stdout/stderr
payload = {
    "call_id": call_id,
    "aggregated_output": truncate_output(aggregated_output, 1_000_000),
    "exit_code": exit_code,
    "duration": duration,
    "formatted_output": truncate_output(formatted_output, 50_000),
}
```

**Impact:**
- âœ… Reduces normal events by ~50% (removes duplicate)
- âœ… Simpler data model
- âš ï¸ Breaking change if consumers expect both fields

## Comparison of Strategies

| Strategy | Normal Event Impact | Large Event Impact | Implementation | Breaking? |
|----------|-------------------|-------------------|----------------|-----------|
| **Truncate stdout** | Minimal | Prevents bloat | Easy | No |
| **Truncate all fields** | Minimal | Prevents bloat | Easy | No |
| **Remove duplicates** | 50% reduction | Prevents bloat | Medium | Yes |
| **Limit entire event** | None | Hard cutoff | Hard | No |

## Recommended Implementation Plan

### Phase 1: Immediate (Prevents Future Bloat)

```python
# In the code that creates turn.exec.end events:

MAX_STDOUT = 1_000_000     # 1M chars (~1 MB)
MAX_STDERR = 100_000       # 100K chars
MAX_AGGREGATED = 1_000_000 # 1M chars
MAX_FORMATTED = 50_000     # 50K chars

def truncate(text: str, max_len: int, field_name: str = "output") -> str:
    if len(text) <= max_len:
        return text
    omitted_chars = len(text) - max_len
    omitted_bytes = len(text.encode('utf-8')) - len(text[:max_len].encode('utf-8'))
    return (
        text[:max_len] +
        f"\n\n... [{field_name} truncated: omitted {omitted_chars:,} chars "
        f"({omitted_bytes / 1024 / 1024:.2f} MB)]"
    )

payload = {
    "call_id": call_id,
    "stdout": truncate(stdout, MAX_STDOUT, "stdout"),
    "stderr": truncate(stderr, MAX_STDERR, "stderr"),
    "aggregated_output": truncate(aggregated_output, MAX_AGGREGATED, "aggregated_output"),
    "exit_code": exit_code,
    "duration": duration,
    "formatted_output": truncate(formatted_output, MAX_FORMATTED, "formatted_output"),
}
```

### Phase 2: Optimization (Remove Redundancy)

After Phase 1 is stable, consider removing `aggregated_output` since it's redundant:

```python
payload = {
    "call_id": call_id,
    "stdout": truncate(stdout, MAX_STDOUT, "stdout"),
    "stderr": truncate(stderr, MAX_STDERR, "stderr"),
    # aggregated_output removed - consumers can concat stdout + stderr if needed
    "exit_code": exit_code,
    "duration": duration,
}
```

## Expected Savings

### With 1M char limit on stdout/aggregated_output:

| Scenario | Current Size | New Size | Savings |
|----------|--------------|----------|---------|
| Top 18 events (>5 MB) | 996 MB | ~36 MB | **960 MB** (96%) |
| Average event | 1.11 MB | 1.11 MB | 0 MB (no change) |
| Total log file | 1.25 GB | ~0.3 GB | **~950 MB** (76%) |

### Additional savings from removing duplicates:

| Scenario | With Truncation | After Dedup | Additional Savings |
|----------|----------------|-------------|-------------------|
| Average event | 1.11 MB | ~0.6 MB | ~0.5 MB (45%) |
| Total log file | 0.3 GB | ~0.15 GB | ~0.15 GB (50%) |

## Implementation Checklist

- [ ] Identify code location where `turn.exec.end` payload is created
- [ ] Add `truncate_output()` function
- [ ] Apply truncation to `stdout`, `stderr`, `aggregated_output`, `formatted_output`
- [ ] Test with large output commands (e.g., `cat large_file.log`)
- [ ] Verify truncation markers appear correctly
- [ ] Monitor log file size reduction
- [ ] (Optional) Remove `aggregated_output` field in Phase 2

## Testing Commands

```bash
# Test truncation with large output
codex exec "cat ~/centralized-logs/codex/sse_lines.jsonl"

# Verify event size
tail -1 ~/centralized-logs/codex/sse_lines.jsonl | \
  python -c "import sys, json; print(len(sys.stdin.read()), 'bytes')"

# Check for truncation marker
tail -1 ~/centralized-logs/codex/sse_lines.jsonl | \
  grep "truncated"
```

## Answer to Your Question

> **Q: Limiting the character limit of that payload would be sufficient to lower the size, right?**

**A: Yes, absolutely!**

Specifically, you need to limit:
1. **`payload.stdout`** - Primary culprit (can be 4.61 MB)
2. **`payload.aggregated_output`** - Duplicate of stdout+stderr (can be 4.61 MB)
3. **`payload.formatted_output`** - Usually small but can grow (max 12 KB)

**Recommended limits:**
- `stdout`: **1,000,000 characters** (~1 MB after JSON encoding)
- `aggregated_output`: **1,000,000 characters**
- `formatted_output`: **50,000 characters** (~50 KB)
- `stderr`: **100,000 characters** (~100 KB)

This will:
- âœ… Prevent the 96 MB outliers
- âœ… Save ~960 MB from the top 18 events
- âœ… Not affect 98% of normal events (avg is only 31 KB)
- âœ… Provide clear truncation markers for debugging

---

*Generated by: Claude Agent 08c7d791-36f6-4728-86dd-259f9d28a1ef*
*Analysis Tools: `ai/generated_code/analyze_exec_end_structure.py`*
